{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "861f1389",
   "metadata": {},
   "source": [
    "# 합성곱 신경망\n",
    "* 합성곱 신경망은 크게 합성곱층과(Convolution layer)와 풀링층(Pooling layer)으로 구성됨\n",
    "* 아래의 그림은 합성곱 신경망의 일반적인 예를 보여줍니다.\n",
    "\n",
    "![img](https://wikidocs.net/images/page/62306/convpooling.PNG)\n",
    "\n",
    "* 위의 그림에서 CONV는 합성곱 연산을 의미하고, 합성곱 연산의 결과가 활성화 함수 ReLU를 지남(합성곱층)\n",
    "* 그 후에 POOL이라는 구간을 지나는데 이는 풀링 연산을 의미하며 풀링층이라고 함\n",
    "\n",
    "* 합성곱 신경망은 이미지 처리에 탁월한 성능을 보이는 신경망임\n",
    "* 이미지 처리를 하기 위해서 앞서 배운 다층 퍼셉트론을 사용할 수는 있지만 한계가 있었음\n",
    "* 예를 들어, 알파벳 손글씨를 분류하는 어떤 문제가 있을때, 아래의 그림은 알파벳 Y를 비교적 정자로 쓴 손글씨와 다소 휘갈겨 쓴 손글씨 두 개를 2차원 텐서인 행렬로 표현한 것\n",
    "![img](https://wikidocs.net/images/page/64066/conv0.png)\n",
    "\n",
    "* 사람이 보기에는 두 그림 모두 알파벳 Y로 손쉽게 판단이 가능하지만, 기계가 보기에는 각 픽셀마다 가진 값이 거의 상이하므로 완전히 다른 값을 가진 입력으로 판단함\n",
    "* 이미지라는 것은 위와 같이 같은 대상이라도 휘어지거나, 이동되었거나, 방향이 뒤틀렸거나 등 다양한 변형이 존재함\n",
    "* 다층 퍼셉트론은 몇 가지 픽셀만 값이 달라져도 민감하게 예측에 영향을 받는다는 단점이 있음\n",
    "\n",
    "\n",
    "* 위 손글씨를 다층 퍼셉트론으로 분류한다고 하면, 이미지를 1차원 텐서인 벡터로 변환하고 다층 퍼셉트론의 입력층으로 사용해야 함\n",
    "* 두번째 손글씨를 다층 퍼셉트론으로 분류하기 위해서 벡터로 바꾸면 다음과 같음\n",
    "![img](https://wikidocs.net/images/page/64066/conv1.png)\n",
    "\n",
    "* 1차원으로 변환된 결과는 사람이 보기에도 이게 원래 어떤 이미지였는지 알아보기가 어려움\n",
    "* 위와 같이 결과는 변환 전에 가지고 있던 공간적인 구조(spatial structure) 정보가 유실된 상태\n",
    "* 여기서 공간적인 구조 정보라는 것은 거리가 가까운 어떤 픽셀들끼리는 어떤 연관이 있고, 어떤 픽셀들끼리는 값이 비슷하거나 등을 포함하고 있음\n",
    "* 결국 이미지의 공간적인 구조 정보를 보존하면서 학습할 수 있는 방법이 필요해졌고, 이를 위해 사용하는 것이 합성곱 신경망임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ccabd7",
   "metadata": {},
   "source": [
    "## 채널\n",
    "* 기계는 글자나 이미지보다 숫자. 다시 말해, 텐서를 더 잘 처리할 수 있음\n",
    "* 이미지는 (높이, 너비, 채널)이라는 3차원 텐서임\n",
    "* 여기서 높이는 이미지의 세로 방향 픽셀 수, 너비는 이미지의 가로 방향 픽셀 수, 채널은 색 성분을 의미함\n",
    "* 흑백 이미지는 채널 수가 1이며, 각 픽셀은 0부터 255 사이의 값을 가짐 아래는 28 × 28 픽셀의 손글씨 데이터를 보여줌\n",
    "![img](https://wikidocs.net/images/page/64066/conv2.png)\n",
    "* 위 손글씨 데이터는 흑백 이미지므로 채널 수가 1임을 고려하면 (28 × 28 × 1)의 크기를 가지는 3차원 텐서임\n",
    "* 그렇다면 흑백이 아니라 우리가 통상적으로 접하게 되는 컬러 이미지는 어떨까요? 컬러 이미지는 적색(Red), 녹색(Green), 청색(Blue) 채널 수가 3개임\n",
    "![img](https://wikidocs.net/images/page/64066/conv3.png)\n",
    "* 하나의 픽셀은 세 가지 색깔, 삼원색의 조합으로 이루어짐 \n",
    "* 만약, 높이가 28, 너비가 28인 컬러 이미지가 있다면 이 이미지의 텐서는 (28 × 28 × 3)의 크기를 가지는 3차원 텐서임\n",
    "* 채널은 때로는 깊이(depth)라고도 하며, 이 경우 이미지는 (높이, 너비, 깊이)라는 3차원 텐서로 표현됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c00b17",
   "metadata": {},
   "source": [
    "## 합성곱 연산(Convolution)\n",
    "* 합성곱층은 합성곱 연산을 통해서 이미지의 특징을 추출하는 역할을 함\n",
    "* 합성곱은 영어로 컨볼루션이라고도 불리는데, 커널(kernel) 또는 필터(filter)라는  크기의 행렬로 높이너비 크기의 이미지를 처음부터 끝까지 훑으면서 크기의 겹쳐지는 부분의 각 이미지와 커널의 원소의 값을 곱해서 모두 더한 값을 출력으로 하는 것을 말함\n",
    "* 이때, 이미지의 가장 왼쪽 위부터 가장 오른쪽까지 순차적으로 훑음\n",
    "* __커널(kernel)은 일반적으로 3 × 3 또는 5 × 5__를 사용함\n",
    "*  아래는  크기의 커널로 의 이미지 행렬에 합성곱 연산을 수행하는 과정을 보여줌\n",
    "* 한 번의 연산을 1 스텝(step)이라고 하였을 때, 합성곱 연산의 네번째 스텝까지 이미지와 식으로 나타내었음\n",
    "![img](./img/img49.png)\n",
    "\n",
    "## 특성맵\n",
    "\n",
    "* 위와 같이 입력으로부터 커널을 사용하여 합성곱 연산을 통해 나온 결과를 특성 맵(feature map)이라고 함\n",
    "* 위의 예제에서는 커널의 크기가 3 × 3이었지만, 커널의 크기는 사용자가 정할 수 있음\n",
    "* 또한 커널의 이동 범위가 위의 예제에서는 한 칸이었지만, 이 또한 사용자가 정할 수 있음 이러한 이동 범위를 __스트라이드(stride)__라고 함\n",
    "* 아래의 예제는 스트라이드가 2일 경우에 5 × 5 이미지에 합성곱 연산을 수행하는 3 × 3 커널의 움직임을 보여줌 최종적으로 2 × 2의 크기의 특성 맵을 얻음\n",
    "![img](https://wikidocs.net/images/page/64066/conv9.png)\n",
    "\n",
    "## 패딩(padding)\n",
    "\n",
    "* 위의 예에서 5 × 5 이미지에 3 × 3의 커널로 합성곱 연산을 하였을 때, 스트라이드가 1일 경우에는 3 × 3의 특성 맵을 얻었음\n",
    "* 이와 같이 합성곱 연산의 결과로 얻은 특성 맵은 입력보다 크기가 작아진다는 특징이 있음\n",
    "* 만약, 합성곱 층을 여러개 쌓았다면 최종적으로 얻은 특성 맵은 초기 입력보다 매우 작아진 상태가 되어버림\n",
    "* 합성곱 연산 이후에도 특성 맵의 크기가 입력의 크기와 동일하게 유지되도록 하고 싶다면 패딩(padding)을 사용하면 됨\n",
    "\n",
    "![img](https://wikidocs.net/images/page/64066/conv10.png)\n",
    "\n",
    "* 패딩은 (합성곱 연산을 하기 전에) 입력의 가장자리에 지정된 개수의 폭만큼 행과 열을 추가해주는 것을 말함\n",
    "* 주로 값을 0으로 채우는 제로 패딩(zero padding)을 사용 \n",
    "* 그림에는 5 × 5 이미지에 1폭짜리 제로 패딩을 사용하여 위, 아래에 하나의 행을 좌, 우에 하나의 열을 추가한 모습을 보여줌\n",
    "\n",
    "* 3 × 3 크기의 커널을 사용한다면 1폭짜리 제로 패딩으로, 5 × 5 크기의 커널을 사용한다면 2폭 짜리 제로 패딩으로 입력과 특성 맵의 크기를 보존할 수 있음\n",
    "* 5 × 5 크기의 이미지에 1폭짜리 제로 패딩을 하면 7 × 7 이미지가 되는데, 여기에 3 × 3의 커널을 사용하여 1 스트라이드로 합성곱을 한 후의 특성 맵은 기존의 입력 이미지의 크기와 같은 5 × 5가 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d828d4d",
   "metadata": {},
   "source": [
    "## 가중치\n",
    "* 다층 퍼셉트론으로 3 × 3 이미지를 처리한다고 가정\n",
    "* 우선 이미지를 1차원 텐서인 벡터로 만들면, 3 × 3 = 9가 되므로 입력층은 9개의 뉴런을 가짐\n",
    "* 또한, 4개의 뉴론을 가지는 은닉층을 추가한다고 해보면 아래와 같음\n",
    "\n",
    "![img](https://wikidocs.net/images/page/64066/conv11.png)\n",
    "\n",
    "\n",
    "* 위에서 각 연결선은 가중치를 의미하므로, 위의 그림에서는 9 × 4 = 36개의 가중치를 가짐\n",
    "* 이제 비교를 위해 합성곱 신경망으로 3 × 3 이미지를 처리에 2 × 2 커널을 사용하고, 스트라이드는 1로 한 경우를 보자\n",
    "\n",
    "![img](https://wikidocs.net/images/page/64066/conv12.png)\n",
    "\n",
    "* 사실 합성곱 신경망에서 가중치는 커널 행렬의 원소들임\n",
    "* 이를 인공 신경망의 형태로 표현한다면 다음과 같이 표현할 수 있음\n",
    "\n",
    "![img](https://wikidocs.net/images/page/64066/conv13.png)\n",
    "\n",
    "이미지 전체를 훑으면서 사용되는 가중치는 $W_0, W_1, W_2, W_3$  4개 뿐임 \n",
    "* 각 합성곱 연산마다 이미지의 모든 픽셀을 사용하는 것이 아니라, 커널과 맵핑되는 픽셀만을 입력으로 사용함\n",
    "* 합성곱 신경망은 다층 퍼셉트론을 사용할 때보다 훨씬 적은 수의 가중치를 사용하며 공간적 구조 정보를 보존한다는 특징이 있음\n",
    "\n",
    "## 특성 맵의 크기 계산 방법\n",
    "\n",
    "* 입력의 크기와 커널의 크기, 그리고 스트라이드의 값만 알면 합성곱 연산의 결과인 특성 맵의 크기를 계산할 수 있음\n",
    "\n",
    "* $I_h$: 입력의 높이\n",
    "*  $I_w$: 입력의 너비\n",
    "*  $K_h$: 커널의 높이\n",
    "* $K_w$: 커널의 너비\n",
    "* $S$: 스트라이드\n",
    "* $O_h$ : 특성 맵의 높이\n",
    "* $O_w$ : 특성 맵의 너비\n",
    "* 특성 맵의 높이와 너비는 아래와 같음\n",
    "$$O_{h} = floor(\\frac{I_{h} - K_{h}}{S}+1)=\\\\ \\frac{(입력의 너비 - 커널 크기)}{스트라이드 크기} + 1$$ \n",
    "$$O_{w} = floor(\\frac{I_{w} - K_{w}}{S}+1)$$\n",
    "\n",
    "* 첫번째 예제의 경우 5 × 5 크기의 이미지에 3 × 3 커널을 사용하고 스트라이드 1로 합성곱 연산을 했음 \n",
    "* 즉 특성 맵의 크기는 (5 - 3 + 1 ) × (5 - 3 + 1) = 3 × 3임\n",
    "\n",
    "* 패딩의 폭을 라고 하고, 패딩까지 고려한 식은 다음과 같음\n",
    "$$O_{h} = floor(\\frac{I_{h} - K_{h} + 2P}{S}+1)$$\n",
    "$$O_{w} = floor(\\frac{I_{w} - K_{w} + 2P}{S}+1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b9f77c",
   "metadata": {},
   "source": [
    "## 다수의 채널을 가진 경우의 합성곱 연산\n",
    "* 실제로 합성곱 연산의 입력은 '다수의 채널을 가진' 이미지 또는 이전 연산의 결과로 나온 특성 맵임\n",
    "* 다수의 채널을 가진 입력 데이터를 가지고 합성곱 연산을 한다고 하면 커널의 채널 수도 입력의 채널 수만큼 존재해야 함\n",
    "* __입력 데이터의 채널 수와 커널의 채널 수__는 같아야 함\n",
    "* 채널 수가 같으므로 합성곱 연산을 채널마다 수행\n",
    "\n",
    "![img](https://wikidocs.net/images/page/64066/conv15.png)\n",
    "\n",
    "* 3개의 채널을 가진 입력 데이터와 3개의 채널을 가진 커널의 합성곱 연산을 보여줌\n",
    "* 커널의 각 채널끼리의 크기는 같아야 함\n",
    "* 각 채널 간 합성곱 연산을 마치고, 그 결과를 모두 더해서 하나의 채널을 가지는 특성 맵을 만듬\n",
    "* 주의할 점은 위의 연산에서 사용되는 커널은 3개의 커널이 아니라 3개의 채널을 가진 1개의 커널이라는 점\n",
    "* 위 그림에서는 높이 3, 너비 3, 채널 3의 입력이 높이 2, 너비 2, 채널 3의 커널과 합성곱 연산을 하여 높이 2, 너비 2, 채널 1의 특성 맵을 얻는다는 의미임\n",
    "* 합성곱 연산의 결과로 얻은 특성 맵의 채널 차원은 RGB 채널 등과 같은 컬러의 의미를 담고 있지는 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2ba3c7",
   "metadata": {},
   "source": [
    "## 풀링\n",
    "* 일반적으로 합성곱 층(합성곱 연산 + 활성화 함수) 다음에는 풀링 층을 추가하는 것이 일반적\n",
    "* 풀링 층에서는 특성 맵을 다운샘플링하여 특성 맵의 크기를 줄이는 풀링 연산이 이루어짐\n",
    "* 풀링 연산에는 일반적으로 최대 풀링(max pooling)과 평균 풀링(average pooling)이 사용됨\n",
    "\n",
    "![img](https://wikidocs.net/images/page/62306/maxpooling.PNG)\n",
    "\n",
    "* 풀링 연산에서도 합성곱 연산과 마찬가지로 커널과 스트라이드의 개념을 가짐\n",
    "* 위의 그림은 스트라이드가 2일 때, 2 x 2 크기 커널로 맥스 풀링 연산을 했을 때 특성맵이 절반의 크기로 다운샘플링되는 것을 보여줌\n",
    "* 맥스 풀링은 커널과 겹치는 영역 안에서 최대값을 추출하는 방식으로 다운샘플링함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9bfff3",
   "metadata": {},
   "source": [
    "# CNN으로 MNIST 분류하기\n",
    "* 합성곱(nn.Cov2d) + 활성화 함수(nn.ReLU)를 하나의 합성곱 층으로 보고, 맥스풀링(nn.MaxPoold2d)은 풀링 층으로 별도로 명명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe3c9eb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-b46a5b7b390a>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-b46a5b7b390a>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    합성곱(in_channel = 1, out_channel = 32, kernel_size=3, stride=1, padding=1) + 활성화 함수 ReLU\u001b[0m\n\u001b[0m                                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 1번 레이어 : 합성곱층(Convolutional layer)\n",
    "합성곱(in_channel = 1, out_channel = 32, kernel_size=3, stride=1, padding=1) + 활성화 함수 ReLU\n",
    "맥스풀링(kernel_size=2, stride=2))\n",
    "\n",
    "# 2번 레이어 : 합성곱층(Convolutional layer)\n",
    "합성곱(in_channel = 32, out_channel = 64, kernel_size=3, stride=1, padding=1) + 활성화 함수 ReLU\n",
    "맥스풀링(kernel_size=2, stride=2))\n",
    "\n",
    "# 3번 레이어 : 전결합층(Fully-Connected layer)\n",
    "특성맵을 펼친다. # batch_size × 7 × 7 × 64 → batch_size × 3136\n",
    "전결합층(뉴런 10개) + 활성화 함수 Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c8659ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b746d24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텐서의 크기 : torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# 배치 크기 × 채널 × 높이(height) × 너비(widht)의 크기의 텐서를 선언\n",
    "inputs = torch.Tensor(1, 1, 28, 28)\n",
    "print('텐서의 크기 : {}'.format(inputs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58db8c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 합성곱 층 선언\n",
    "conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "print(conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8947f8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "# 두번째 합성곱 층 선언\n",
    "conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "print(conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1e72026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
     ]
    }
   ],
   "source": [
    "# 풀링층 선언\n",
    "pool = nn.MaxPool2d(2)\n",
    "print(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd5a2b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "out = conv1(inputs)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bfa16c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "out = pool(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2e66b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "out = conv2(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2a397b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "out = pool(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "616dafe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 64 7 7\n"
     ]
    }
   ],
   "source": [
    "print(out.size(0),out.size(1), out.size(2), out.size(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1162712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3136])\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 차원인 배치 차원은 그대로 두고 나머지는 펼쳐라\n",
    "out = out.view(out.size(0), -1) \n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d13ad560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "fc = nn.Linear(3136, 10) # input_dim = 3,136, output_dim = 10\n",
    "out = fc(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e65a63",
   "metadata": {},
   "source": [
    "## CNN으로 MNIST 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c0b0c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d554b4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 랜덤 시드 고정\n",
    "torch.manual_seed(777)\n",
    "\n",
    "# GPU 사용 가능일 경우 랜덤 시드 고정\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46247957",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습 파라미터 설정\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee3df778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a627406fbae54eb3b6cdc796c6c830fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a42f19d1765a4565adadf4378d71e55f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc887b51ff0c42f5ab0c020f2ddba155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91eb4c8f8b344d62b20444e132706326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dilab/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1631630788697/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "#데이터 정의\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n",
    "                          train=True, # True를 지정하면 훈련 데이터로 다운로드\n",
    "                          transform=transforms.ToTensor(), # 텐서로 변환\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n",
    "                         train=False, # False를 지정하면 테스트 데이터로 다운로드\n",
    "                         transform=transforms.ToTensor(), # 텐서로 변환\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5e023de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 로더 정의\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff2d85b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 정의\n",
    "class CNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # 첫번째층\n",
    "        # ImgIn shape=(?, 28, 28, 1)\n",
    "        #    Conv     -> (?, 28, 28, 32)\n",
    "        #    Pool     -> (?, 14, 14, 32)\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        # 두번째층\n",
    "        # ImgIn shape=(?, 14, 14, 32)\n",
    "        #    Conv      ->(?, 14, 14, 64)\n",
    "        #    Pool      ->(?, 7, 7, 64)\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        # 전결합층 7x7x64 inputs -> 10 outputs\n",
    "        self.fc = torch.nn.Linear(7 * 7 * 64, 10, bias=True)\n",
    "\n",
    "        # 전결합층 한정으로 가중치 초기화\n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)   # 전결합층을 위해서 Flatten\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "637c32cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 모델 정의\n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7cd797b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=3136, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ee53ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#비용함수와 최적화 함수 정의\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)    # 비용 함수에 소프트맥스 함수 포함되어져 있음.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c76d7638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 배치의 수 : 600 배치당 크기: 100\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "print('총 배치의 수 : {}'.format(total_batch), '배치당 크기: {}'.format(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "102b497a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1] cost = 0.225655779\n",
      "[Epoch:    2] cost = 0.0630104691\n",
      "[Epoch:    3] cost = 0.0462511703\n",
      "[Epoch:    4] cost = 0.0374729298\n",
      "[Epoch:    5] cost = 0.0313367248\n",
      "[Epoch:    6] cost = 0.0261164345\n",
      "[Epoch:    7] cost = 0.0217489079\n",
      "[Epoch:    8] cost = 0.0181486048\n",
      "[Epoch:    9] cost = 0.016144082\n",
      "[Epoch:   10] cost = 0.0132617569\n",
      "[Epoch:   11] cost = 0.0101653645\n",
      "[Epoch:   12] cost = 0.00965886097\n",
      "[Epoch:   13] cost = 0.00801612251\n",
      "[Epoch:   14] cost = 0.006138884\n",
      "[Epoch:   15] cost = 0.00650928356\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in data_loader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y느 ㄴ레이블.\n",
    "        # image is already size of (28x28), no reshape\n",
    "        # label is not one-hot encoded\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "89f6e45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dilab/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py:67: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/home/dilab/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py:57: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9878000020980835\n"
     ]
    }
   ],
   "source": [
    "# 학습을 진행하지 않을 것이므로 torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afa8279",
   "metadata": {},
   "source": [
    "# 더 깊은 CNN으로 MNIST 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ff93b612",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-46-f084675da077>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-46-f084675da077>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    합성곱(in_channel = 1, out_channel = 32, kernel_size=3, stride=1, padding=1) + 활성화 함수 ReLU\u001b[0m\n\u001b[0m                                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 1번 레이어 : 합성곱층(Convolutional layer)\n",
    "합성곱(in_channel = 1, out_channel = 32, kernel_size=3, stride=1, padding=1) + 활성화 함수 ReLU\n",
    "맥스풀링(kernel_size=2, stride=2))\n",
    "\n",
    "# 2번 레이어 : 합성곱층(Convolutional layer)\n",
    "합성곱(in_channel = 32, out_channel = 64, kernel_size=3, stride=1, padding=1) + 활성화 함수 ReLU\n",
    "맥스풀링(kernel_size=2, stride=2))\n",
    "\n",
    "# 3번 레이어 : 합성곱층(Convolutional layer)\n",
    "합성곱(in_channel = 64, out_channel = 128, kernel_size=3, stride=1, padding=1) + 활성화 함수 ReLU\n",
    "맥스풀링(kernel_size=2, stride=2, padding=1))\n",
    "\n",
    "# 4번 레이어 : 전결합층(Fully-Connected layer)\n",
    "특성맵을 펼친다. # batch_size × 4 × 4 × 128 → batch_size × 2048\n",
    "전결합층(뉴런 625개) + 활성화 함수 ReLU\n",
    "\n",
    "# 5번 레이어 : 전결합층(Fully-Connected layer)\n",
    "전결합층(뉴런 10개) + 활성화 함수 Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "750a6d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "56bc251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 랜덤 시드 고정\n",
    "torch.manual_seed(777)\n",
    "\n",
    "# GPU 사용 가능일 경우 랜덤 시드 고정\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ccb1f75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7c0e84c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n",
    "                          train=True, # True를 지정하면 훈련 데이터로 다운로드\n",
    "                          transform=transforms.ToTensor(), # 텐서로 변환\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n",
    "                         train=False, # False를 지정하면 테스트 데이터로 다운로드\n",
    "                         transform=transforms.ToTensor(), # 텐서로 변환\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f9c3710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a49edb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.keep_prob = 0.5\n",
    "        # L1 ImgIn shape=(?, 28, 28, 1)\n",
    "        #    Conv     -> (?, 28, 28, 32)\n",
    "        #    Pool     -> (?, 14, 14, 32)\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        # L2 ImgIn shape=(?, 14, 14, 32)\n",
    "        #    Conv      ->(?, 14, 14, 64)\n",
    "        #    Pool      ->(?, 7, 7, 64)\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        # L3 ImgIn shape=(?, 7, 7, 64)\n",
    "        #    Conv      ->(?, 7, 7, 128)\n",
    "        #    Pool      ->(?, 4, 4, 128)\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1))\n",
    "\n",
    "        # L4 FC 4x4x128 inputs -> 625 outputs\n",
    "        self.fc1 = torch.nn.Linear(4 * 4 * 128, 625, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            self.fc1,\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=1 - self.keep_prob))\n",
    "        # L5 Final FC 625 inputs -> 10 outputs\n",
    "        self.fc2 = torch.nn.Linear(625, 10, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)   # Flatten them for FC\n",
    "        out = self.layer4(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "290e1da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 모델 정의\n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "96c7bd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().to(device)    # 비용 함수에 소프트맥스 함수 포함되어져 있음.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "faf54756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1] cost = 0.191501305\n",
      "[Epoch:    2] cost = 0.0546777695\n",
      "[Epoch:    3] cost = 0.0378060713\n",
      "[Epoch:    4] cost = 0.0296842624\n",
      "[Epoch:    5] cost = 0.0253740754\n",
      "[Epoch:    6] cost = 0.0195633452\n",
      "[Epoch:    7] cost = 0.017463183\n",
      "[Epoch:    8] cost = 0.0153190624\n",
      "[Epoch:    9] cost = 0.0142144356\n",
      "[Epoch:   10] cost = 0.0106165931\n",
      "[Epoch:   11] cost = 0.0107275797\n",
      "[Epoch:   12] cost = 0.00979873072\n",
      "[Epoch:   13] cost = 0.00828688405\n",
      "[Epoch:   14] cost = 0.00793609116\n",
      "[Epoch:   15] cost = 0.00855754223\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in data_loader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y느 ㄴ레이블.\n",
    "        # image is already size of (28x28), no reshape\n",
    "        # label is not one-hot encoded\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "18ca1756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9861999750137329\n"
     ]
    }
   ],
   "source": [
    "# 학습을 진행하지 않을 것이므로 torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b44fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51895f25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
